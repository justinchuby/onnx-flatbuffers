# automatically generated by the FlatBuffers compiler, do not modify

# namespace: TypeProto_

import flatbuffers
from flatbuffers.compat import import_numpy
np = import_numpy()

class SparseTensor(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAs(cls, buf, offset=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = SparseTensor()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsSparseTensor(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)
    # SparseTensor
    def Init(self, buf, pos):
        self._tab = flatbuffers.table.Table(buf, pos)

    # SparseTensor
    def ElemType(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # SparseTensor
    def Shape(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            x = self._tab.Indirect(o + self._tab.Pos)
            from onnxfbs.protos.TensorShapeProto import TensorShapeProto
            obj = TensorShapeProto()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

def SparseTensorStart(builder):
    builder.StartObject(2)

def Start(builder):
    SparseTensorStart(builder)

def SparseTensorAddElemType(builder, elemType):
    builder.PrependInt32Slot(0, elemType, 0)

def AddElemType(builder, elemType):
    SparseTensorAddElemType(builder, elemType)

def SparseTensorAddShape(builder, shape):
    builder.PrependUOffsetTRelativeSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(shape), 0)

def AddShape(builder, shape):
    SparseTensorAddShape(builder, shape)

def SparseTensorEnd(builder):
    return builder.EndObject()

def End(builder):
    return SparseTensorEnd(builder)

import onnx.TensorShapeProto
try:
    from typing import Optional
except:
    pass

class SparseTensorT(object):

    # SparseTensorT
    def __init__(self):
        self.elemType = 0  # type: int
        self.shape = None  # type: Optional[onnx.TensorShapeProto.TensorShapeProtoT]

    @classmethod
    def InitFromBuf(cls, buf, pos):
        sparseTensor = SparseTensor()
        sparseTensor.Init(buf, pos)
        return cls.InitFromObj(sparseTensor)

    @classmethod
    def InitFromPackedBuf(cls, buf, pos=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, pos)
        return cls.InitFromBuf(buf, pos+n)

    @classmethod
    def InitFromObj(cls, sparseTensor):
        x = SparseTensorT()
        x._UnPack(sparseTensor)
        return x

    # SparseTensorT
    def _UnPack(self, sparseTensor):
        if sparseTensor is None:
            return
        self.elemType = sparseTensor.ElemType()
        if sparseTensor.Shape() is not None:
            self.shape = onnx.TensorShapeProto.TensorShapeProtoT.InitFromObj(sparseTensor.Shape())

    # SparseTensorT
    def Pack(self, builder):
        if self.shape is not None:
            shape = self.shape.Pack(builder)
        SparseTensorStart(builder)
        SparseTensorAddElemType(builder, self.elemType)
        if self.shape is not None:
            SparseTensorAddShape(builder, shape)
        sparseTensor = SparseTensorEnd(builder)
        return sparseTensor
